================================================================================
  FLOW OF PROGRAM â€” Kavita AI Voice Appointment Agent
================================================================================
  Step-by-step trace of everything that happens from `python main.py`
  through a complete conversation to the final summary and shutdown.
================================================================================


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  PHASE 1: STARTUP                                                 [main.py]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  1. main() is called
     â”‚
     â”œâ”€ load_dotenv()
     â”‚    Reads .env file â†’ sets AZURE_SPEECH_KEY, OPENAI_API_KEY,
     â”‚    CARTESIA_API_KEY, AGENT_NAME, OPENAI_MODEL, AVATAR_PORT
     â”‚
     â”œâ”€ Generate call_id (random 8-char UUID, e.g. "daa2916a")
     â”‚
     â”œâ”€ Create shared IPC objects via multiprocessing:
     â”‚    â”œâ”€ term_event    = mp.Event()     # signals full shutdown
     â”‚    â”œâ”€ stop_event    = mp.Event()     # interrupts current TTS playback
     â”‚    â”œâ”€ start_event   = mp.Event()     # blocks until browser clicks Start
     â”‚    â”œâ”€ mp_commands_queue   = Manager().Queue()   # main â†’ speaker
     â”‚    â”œâ”€ agent_status_queue  = Manager().Queue()   # speaker â†’ main
     â”‚    â””â”€ avatar_queue        = Manager().Queue()   # both â†’ avatar server
     â”‚
     â”œâ”€ Register SIGINT handler (Ctrl+C sets all events)
     â”‚
     â”œâ”€ Spawn Speaker Process (multiprocessing.Process, daemon=True)
     â”‚    target = speaker_proc(
     â”‚        mp_commands_queue, stop_event, term_event,
     â”‚        agent_status_queue, agent_name, language,
     â”‚        avatar_queue, start_event
     â”‚    )
     â”‚    Speaker starts and immediately WAITS for start_event.
     â”‚
     â””â”€ asyncio.run(async_main(...))
          â”‚
          â”œâ”€ Create AvatarServer(avatar_queue, start_event)
          â”‚    â””â”€ aiohttp app with:
          â”‚         GET  /    â†’ serves avatar/index.html
          â”‚         GET  /ws  â†’ WebSocket handler
          â”‚    â””â”€ Starts listening on port 8765
          â”‚    â””â”€ Prints: "Avatar server running at http://localhost:8765"
          â”‚
          â””â”€ await run_conversation_manager(...)  (see Phase 2)


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  PHASE 2: INITIALIZATION                          [conversation_manager.py]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  run_conversation_manager() starts:
     â”‚
     â”œâ”€ Select microphone device
     â”‚    sounddevice.query_devices() â†’ picks default input
     â”‚    Prints: "Using: MacBook Pro Microphone"
     â”‚
     â”œâ”€ Initialize Azure STT
     â”‚    SimpleAzureSTT(threshold=50, language="en-US", sample_rate=16000)
     â”‚    â””â”€ Creates SpeechConfig from AZURE_SPEECH_KEY + AZURE_SPEECH_REGION
     â”‚    â””â”€ Creates PushAudioInputStream (16kHz, 16-bit, mono)
     â”‚    â””â”€ Creates AudioConfig from push stream
     â”‚    â””â”€ Creates SpeechRecognizer
     â”‚    â””â”€ Hooks callbacks: recognized, recognizing, session_started/stopped
     â”‚    â””â”€ start_continuous_recognition_async()
     â”‚    â””â”€ Prints: "Recognition started successfully"
     â”‚
     â”œâ”€ Initialize MicStream(samplerate=16000, blocksize=320, channels=1)
     â”‚
     â”œâ”€ Initialize ConversationalLLM(agent_name="kavita")
     â”‚    â””â”€ Sets up OpenAI client with OPENAI_API_KEY
     â”‚    â””â”€ Builds system prompt with today's date
     â”‚    â””â”€ Initializes messages = [system_message]
     â”‚
     â”œâ”€ Initialize ConversationLogger(call_id)
     â”œâ”€ Initialize ConversationSummarizer()
     â”‚
     â””â”€ *** WAIT FOR BROWSER START ***
          â”‚
          â”‚  Prints: "Waiting for 'Start Conversation' in browser..."
          â”‚  Polls start_event.is_set() every 200ms
          â”‚
          â”‚  (Meanwhile, user opens http://localhost:8765 in browser)
          â”‚  (Browser connects WebSocket to /ws)
          â”‚  (User clicks Start button)
          â”‚  (Browser sends: {"action": "start"})
          â”‚  (AvatarServer._ws_handler receives it)
          â”‚  (Calls start_event.set())
          â”‚  (Broadcasts {"type": "conversation_started"} â†’ browser hides overlay)
          â”‚
          â””â”€ start_event is now set â†’ both speaker + conv_manager unblock


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  PHASE 3: GREETING                                          [speaker.py]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Speaker process (unblocked by start_event):
     â”‚
     â”œâ”€ Initialize CartesiaTTS
     â”‚    â””â”€ WebSocket connection to Cartesia API
     â”‚
     â”œâ”€ Initialize PyAudio output stream
     â”‚    â””â”€ format=paInt16, channels=1, rate=22050
     â”‚
     â”œâ”€ Synthesize greeting:
     â”‚    text = "Hello! Welcome to our clinic. Could you please share
     â”‚            your 4-digit user ID?"
     â”‚
     â”‚    CartesiaTTS.stream(text) â†’ yields audio chunks
     â”‚    For each chunk:
     â”‚    â”‚  â”œâ”€ PyAudio stream.write(chunk)        â†’ plays audio
     â”‚    â”‚  â”œâ”€ audioop.rms(chunk, 2) â†’ energy     â†’ measures volume
     â”‚    â”‚  â””â”€ avatar_queue.put({"type": "audio_energy", "energy": 0.0-1.0})
     â”‚    â”‚                                         â†’ browser animates mouth
     â”‚    â”‚
     â”‚    After all chunks:
     â”‚    â”œâ”€ avatar_queue.put({"type": "speaking_end"})
     â”‚    â””â”€ agent_status_queue.put({"action": "ready"})
     â”‚
     â””â”€ Enters command loop: polls mp_commands_queue for work

  Back in conversation_manager:
     â”‚
     â”œâ”€ _wait_for_ready() â€” drains agent_status_queue until "ready"
     â”œâ”€ avatar_queue.put({"type": "listening"})  â†’ green ring in browser
     â”œâ”€ Prints: "Ready â€” speak anytime!"
     â”‚
     â””â”€ Enters main conversation loop


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  PHASE 4: MAIN CONVERSATION LOOP                 [conversation_manager.py]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  The loop runs until term_event.is_set() or conversation ends.
  Each iteration takes ~20ms (driven by mic chunk arrival).

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                    LOOP ITERATION                                â”‚
  â”‚                                                                  â”‚
  â”‚  A. Read mic chunk (via run_in_executor â€” non-blocking)         â”‚
  â”‚     â””â”€ chunk = await loop.run_in_executor(None, _next_chunk)    â”‚
  â”‚     â””â”€ _next_chunk() calls next(mic_iter) in thread pool        â”‚
  â”‚     â””â”€ Returns 320 bytes (10ms of 16kHz 16-bit mono)            â”‚
  â”‚                                                                  â”‚
  â”‚  B. Feed to STT                                                  â”‚
  â”‚     â””â”€ await stt.send_audio(chunk)                               â”‚
  â”‚     â””â”€ push_stream.write(chunk) â†’ Azure processes server-side   â”‚
  â”‚                                                                  â”‚
  â”‚  C. Drain agent_status_queue (non-blocking)                     â”‚
  â”‚     â””â”€ "speaking"       â†’ agent_is_speaking = True              â”‚
  â”‚     â””â”€ "done_speaking"  â†’ agent_is_speaking = False             â”‚
  â”‚     â””â”€ "interrupted"    â†’ agent_is_speaking = False             â”‚
  â”‚     â””â”€ Always: reset last_activity_time while agent is speaking â”‚
  â”‚                                                                  â”‚
  â”‚  D. Drain STT results (non-blocking)                            â”‚
  â”‚     â””â”€ stt_queue.get_nowait()                                    â”‚
  â”‚     â””â”€ Appends text to pending_user_text[]                      â”‚
  â”‚     â””â”€ Sets last_stt_time = now                                  â”‚
  â”‚     â””â”€ If agent is speaking â†’ set stop_event (interruption)     â”‚
  â”‚                                                                  â”‚
  â”‚  E. 2-second silence check                                      â”‚
  â”‚     â””â”€ If pending_user_text has content AND                      â”‚
  â”‚        (now - last_stt_time) >= 2.0 seconds:                    â”‚
  â”‚        â†’ Process user utterance (see Phase 5)                    â”‚
  â”‚                                                                  â”‚
  â”‚  F. 45-second inactivity check                                  â”‚
  â”‚     â””â”€ If (now - last_activity_time) > 45s AND not speaking:    â”‚
  â”‚        â†’ Auto-end conversation with goodbye message              â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  PHASE 5: PROCESSING A USER UTTERANCE            [conversation_manager.py]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Triggered when 2 seconds pass after last STT result (silence = user done).

  1. Join fragments:
     full_user_text = " ".join(pending_user_text)
     e.g., "My ID is 1001"
     pending_user_text.clear()

  2. Log and display:
     conv_logger.log_user(full_user_text)
     avatar_queue.put({"type": "user_speaking", "text": full_user_text})
     Prints: "ğŸ‘¤ User: My ID is 1001"

  3. Send to LLM:
     llm_result = llm.get_response(full_user_text)
     â”‚
     â”‚  Inside ConversationalLLM.get_response():
     â”‚  â”œâ”€ Append {"role": "user", "content": text} to messages
     â”‚  â”œâ”€ Call OpenAI chat.completions.create(
     â”‚  â”‚      model="gpt-4o-mini",
     â”‚  â”‚      messages=[system, ...history],
     â”‚  â”‚      tools=APPOINTMENT_TOOLS,    # 8 tool definitions
     â”‚  â”‚      tool_choice="auto",
     â”‚  â”‚      temperature=0.5,
     â”‚  â”‚      max_tokens=100
     â”‚  â”‚  )
     â”‚  â”‚
     â”‚  â”œâ”€ If response has tool_calls:
     â”‚  â”‚    For each tool_call:
     â”‚  â”‚    â”œâ”€ Parse function name + arguments from JSON
     â”‚  â”‚    â”œâ”€ Dispatch to TOOL_DISPATCH[fn_name](**args)
     â”‚  â”‚    â”‚    e.g., identify_user(user_id="1001")
     â”‚  â”‚    â”‚    â†’ reads data/appointments.json
     â”‚  â”‚    â”‚    â†’ returns {"status":"found","user":{...},"active_appointments":[...]}
     â”‚  â”‚    â”œâ”€ Append tool result to messages
     â”‚  â”‚    â””â”€ Log to tool_call_log
     â”‚  â”‚
     â”‚  â”‚  Call OpenAI AGAIN with tool results â†’ LLM generates text response
     â”‚  â”‚  (May chain: e.g., identify_user â†’ fetch_slots in same turn)
     â”‚  â”‚  Loop up to 5 rounds of tool calls.
     â”‚  â”‚
     â”‚  â”œâ”€ If response has tool_call "end_conversation":
     â”‚  â”‚    Set end_conversation = True
     â”‚  â”‚
     â”‚  â””â”€ Return {"response": text, "tool_calls": [...], "end_conversation": bool}

  4. Send tool call events to avatar:
     For each tool_call in llm_result["tool_calls"]:
         avatar_queue.put({
             "type": "tool_call",
             "function": "identify_user",
             "arguments": {"user_id": "1001"},
             "result": {"status": "found", "user": {...}, ...}
         })
     â†’ Browser renders styled tool card with user info, appointments, etc.

  5. Send text to speaker:
     mp_commands_queue.put({
         "action": "speak",
         "text": "Welcome back, Archit! You have 2 appointments. How can I help?",
         "turn_id": 3
     })
     last_activity_time = now  (reset timer)

  6. If end_conversation:
     _wait_for_speaker_done() â†’ blocks until speaker finishes goodbye
     break  â†’ exits main loop â†’ Phase 7


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  PHASE 6: SPEAKER HANDLING                                  [speaker.py]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Speaker process command loop (runs in separate OS process):

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  while not term_event.is_set():                                 â”‚
  â”‚      cmd = mp_commands_queue.get(timeout=0.5)                   â”‚
  â”‚                                                                  â”‚
  â”‚      if cmd["action"] == "speak":                               â”‚
  â”‚          text = cmd["text"]                                      â”‚
  â”‚          turn_id = cmd["turn_id"]                                â”‚
  â”‚                                                                  â”‚
  â”‚          agent_status_queue.put({"action": "speaking"})          â”‚
  â”‚          avatar_queue.put({"type":"speaking_start","text":text}) â”‚
  â”‚                                                                  â”‚
  â”‚          for chunk in CartesiaTTS.stream(text):                 â”‚
  â”‚              if stop_event.is_set():         # interrupted!      â”‚
  â”‚                  stop_event.clear()                              â”‚
  â”‚                  agent_status_queue.put({"action":"interrupted"})â”‚
  â”‚                  break                                           â”‚
  â”‚                                                                  â”‚
  â”‚              pyaudio_stream.write(chunk)      # play audio       â”‚
  â”‚              rms = audioop.rms(chunk, 2)      # measure energy   â”‚
  â”‚              energy = min(1.0, rms / 8000)    # normalize 0-1    â”‚
  â”‚              avatar_queue.put({"type":"audio_energy","energy":e})â”‚
  â”‚                                                                  â”‚
  â”‚          avatar_queue.put({"type": "speaking_end"})             â”‚
  â”‚          agent_status_queue.put({"action": "done_speaking"})    â”‚
  â”‚                                                                  â”‚
  â”‚      if cmd["action"] == "terminate":                           â”‚
  â”‚          break                                                   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  INTERRUPTION FLOW:
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  1. User starts speaking while agent is talking
  2. Azure STT fires a result â†’ stt_queue gets text
  3. Conversation manager drains stt_queue, sees text while agent_is_speaking
  4. Sets stop_event.set()
  5. Speaker sees stop_event in its chunk loop â†’ breaks immediately
  6. Reports "interrupted" via agent_status_queue
  7. Conversation manager picks up the interruption, resets state
  8. User's text is accumulated normally, processed after 2s silence


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  PHASE 7: CONVERSATION END                        [conversation_manager.py]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Triggered by either:
  (a) LLM calls end_conversation tool â†’ end_conv = True
  (b) 45-second user silence timeout

  1. Break out of main loop

  2. Stop STT:
     await stt.stop()
     â””â”€ push_stream.close()
     â””â”€ stop_continuous_recognition_async()

  3. Generate summary:
     summarizer.summarize_from_turns(conv_logger.get_turns())
     â”‚
     â”‚  Inside ConversationSummarizer:
     â”‚  â”œâ”€ Formats all turns into a transcript string
     â”‚  â”œâ”€ Includes tool call details (function names, arguments, results)
     â”‚  â”œâ”€ Sends to OpenAI with summary prompt:
     â”‚  â”‚    "Summarize this conversation. Include:
     â”‚  â”‚     CALLER INTENT / ACTIONS TAKEN / KEY DETAILS / OUTCOME / DURATION"
     â”‚  â””â”€ Returns structured summary text (~1-3 seconds)

  4. Send summary to avatar:
     avatar_queue.put({"type": "summary", "text": summary_text})
     â†’ Browser shows fullscreen summary overlay with:
       â€¢ Call summary text
       â€¢ "Close" button

  5. Log and finalize:
     conv_logger.finalize(summary=summary)
     Print summary to terminal

  6. Terminate speaker:
     mp_commands_queue.put({"action": "terminate"})
     term_event.set()
     â†’ Speaker process breaks out of its loop and exits


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  PHASE 8: SHUTDOWN                                              [main.py]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  async_main() returns â†’ back in main():
     â”‚
     â”œâ”€ term_event.set()     (redundant safety)
     â”œâ”€ stop_event.set()     (redundant safety)
     â”œâ”€ start_event.set()    (unblock if still waiting)
     â”œâ”€ mp_commands_queue.put({"action": "terminate"})
     â”œâ”€ speaker.terminate()  (if still alive)
     â”œâ”€ speaker.join(timeout=3)
     â””â”€ Prints: "Appointment Booking Agent stopped."


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  AVATAR SERVER â€” PARALLEL FLOW                          [avatar/server.py]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Runs as an async task in the SAME event loop as conversation_manager.

  Two concurrent coroutines:

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ 1. aiohttp web server                   â”‚
  â”‚    â€¢ GET /     â†’ serve index.html       â”‚
  â”‚    â€¢ GET /ws   â†’ WebSocket handler      â”‚
  â”‚      - On connect: add to clients set   â”‚
  â”‚      - On message: check for            â”‚
  â”‚        {"action":"start"} â†’ set         â”‚
  â”‚        start_event + broadcast ack      â”‚
  â”‚      - On disconnect: remove client     â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ 2. Queue reader (background task)       â”‚
  â”‚    loop forever:                         â”‚
  â”‚      event = await run_in_executor(      â”‚
  â”‚          None, avatar_queue.get,         â”‚
  â”‚          timeout=0.5                     â”‚
  â”‚      )                                   â”‚
  â”‚      for client in self.clients:         â”‚
  â”‚          await client.send_json(event)   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  Events broadcast to browser:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Event Type           â”‚ What Browser Does                               â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ conversation_started â”‚ Hides start overlay, shows main UI              â”‚
  â”‚ speaking_start       â”‚ Purple ring pulse, adds agent text to transcriptâ”‚
  â”‚ audio_energy         â”‚ Animates mouth (SVG ellipse rx/ry)              â”‚
  â”‚ speaking_end         â”‚ Closes mouth, ring dims to idle                 â”‚
  â”‚ user_speaking        â”‚ Adds user text to transcript (green)            â”‚
  â”‚ listening            â”‚ Green ring, status: "Listening"                 â”‚
  â”‚ tool_call            â”‚ Renders tool card + updates user card on left   â”‚
  â”‚ summary              â”‚ Shows fullscreen summary overlay                â”‚
  â”‚ shutdown             â”‚ Shows "Call ended" in status                    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  APPOINTMENT HANDLER â€” DB & TOOL INTERNALS   [services/appointment_handler.py]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Database: data/appointments.json
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ {                                                            â”‚
  â”‚   "users": {                                                 â”‚
  â”‚     "1001": {"name": "Archit Ojha", "user_id": "1001"},     â”‚
  â”‚     "2045": {"name": "Priya Sharma", "user_id": "2045"}     â”‚
  â”‚   },                                                         â”‚
  â”‚   "appointments": [                                          â”‚
  â”‚     {                                                        â”‚
  â”‚       "appointment_id": "a1b2c3d4",                          â”‚
  â”‚       "user_id": "1001",                                     â”‚
  â”‚       "name": "Archit Ojha",                                 â”‚
  â”‚       "date": "2026-02-10",                                  â”‚
  â”‚       "time": "10:00 AM",                                    â”‚
  â”‚       "purpose": "General checkup",                          â”‚
  â”‚       "status": "booked",          â† or "cancelled"          â”‚
  â”‚       "created_at": "2026-02-07T10:00:00",                   â”‚
  â”‚       "modified_at": null          â† set on cancel/modify    â”‚
  â”‚     }                                                        â”‚
  â”‚   ]                                                          â”‚
  â”‚ }                                                            â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  Slot generation:
    _generate_all_slots("2026-02-12") produces:
    ["09:00 AM", "09:30 AM", "10:00 AM", ... "05:00 PM", "05:30 PM"]
    (18 slots total, 30-min intervals, 9 AM to 6 PM)

  Conflict detection:
    _get_booked_slots() filters appointments where date matches
    AND status == "booked" â†’ returns set of taken time strings.
    A cancelled appointment does NOT block the slot.

  Tool execution chain (example â€” full booking):

  Turn 1: User says "My ID is 1001"
  â””â”€ LLM calls: identify_user(user_id="1001")
     â””â”€ _load_db() â†’ read JSON
     â””â”€ Find "1001" in users â†’ found
     â””â”€ Filter appointments: user_id="1001" AND status="booked"
     â””â”€ Return: {status:"found", user:{...}, active_appointments:[2 items]}

  Turn 2: User says "Book for February 12th"
  â””â”€ LLM calls: fetch_slots(date="2026-02-12")
     â””â”€ _generate_all_slots â†’ 18 slots
     â””â”€ _get_booked_slots â†’ {"11:00 AM"} (Priya's dental cleaning)
     â””â”€ available = 18 - 1 = 17 slots
     â””â”€ Return: {available_slots:[17 items], booked_slots:["11:00 AM"]}
  â””â”€ LLM picks 3 well-spaced slots, responds:
     "I have 9:30 AM, 12 PM, and 3:30 PM. Which works?"

  Turn 3: User says "12 PM"
  â””â”€ LLM calls: book_appointment(
         user_id="1001", name="Archit Ojha",
         date="2026-02-12", time_slot="12:00 PM",
         purpose="Lab visit"
     )
     â””â”€ Validate: "12:00 PM" in _generate_all_slots() â†’ âœ… valid
     â””â”€ Check: "12:00 PM" in _get_booked_slots() â†’ âœ… not taken
     â””â”€ Check: user doesn't already have this slot â†’ âœ…
     â””â”€ Generate appointment_id = uuid4()[:8] â†’ e.g. "f3g4h5i6"
     â””â”€ Append to appointments list
     â””â”€ _save_db() â†’ write updated JSON
     â””â”€ Return: {status:"booked", appointment_id:"f3g4h5i6", ...}


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  COMPLETE EXAMPLE CONVERSATION TRACE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  [Browser]    User clicks "Start Conversation"
  [WSâ†’Server]  {"action":"start"}
  [Server]     start_event.set()
  [WSâ†’Browser] {"type":"conversation_started"}
  [Browser]    Hides start overlay, shows main UI

  [Speaker]    TTS: "Hello! Welcome to our clinic..."
  [WSâ†’Browser] {"type":"speaking_start","text":"Hello! Welcome..."}
  [WSâ†’Browser] {"type":"audio_energy","energy":0.45}  (Ã—20 chunks)
  [WSâ†’Browser] {"type":"speaking_end"}
  [WSâ†’Browser] {"type":"listening"}

  [User]       "My ID is 1001"
  [Azure STT]  recognizing: "my" â†’ "my ID" â†’ "my ID is 1001"
  [Azure STT]  final: "My ID is 1001."
  [ConvMgr]    (2s silence) â†’ processes utterance
  [LLM]        Tool call: identify_user({"user_id":"1001"})
  [Handler]    â†’ {status:"found", user:{name:"Archit Ojha"}, active:[2]}
  [LLM]        "Welcome back, Archit! You have 2 appointments. How can I help?"
  [WSâ†’Browser] {"type":"tool_call","function":"identify_user",...}
  [Browser]    Shows user card: name, ID badge, appointment list
  [Speaker]    TTS plays response

  [User]       "Book for February 12th"
  [LLM]        Tool call: fetch_slots({"date":"2026-02-12"})
  [Handler]    â†’ {available_count:17, booked_slots:["11:00 AM"]}
  [LLM]        "I have 9:30 AM, 12 PM, and 3:30 PM. Which works?"
  [WSâ†’Browser] {"type":"tool_call","function":"fetch_slots",...}
  [Browser]    Shows slot grid: green chips (free) + red chips (booked)
  [Speaker]    TTS plays response

  [User]       "12 PM please"
  [LLM]        Tool call: book_appointment({...date:"2026-02-12",time:"12:00 PM"})
  [Handler]    â†’ {status:"booked", appointment_id:"f3g4h5i6"}
  [LLM]        "Done! Booked Feb 12 at 12 PM. ID: f-3-g-4-h-5-i-6."
  [WSâ†’Browser] {"type":"tool_call","function":"book_appointment",...}
  [Browser]    Adds new appointment to user card on left panel
  [Speaker]    TTS plays confirmation

  [User]       "That's all, bye"
  [LLM]        Tool call: end_conversation({})
  [LLM]        "Thank you, Archit! Have a great day. Goodbye!"
  [Speaker]    TTS plays goodbye
  [ConvMgr]    _wait_for_speaker_done()
  [ConvMgr]    Breaks loop â†’ stops STT

  [Summarizer] Sends full transcript to OpenAI â†’ 1.5s â†’ structured summary
  [WSâ†’Browser] {"type":"summary","text":"Archit (ID 1001) called to book..."}
  [Browser]    Fullscreen summary overlay appears

  [ConvMgr]    Sends terminate to speaker
  [Speaker]    Exits
  [main.py]    "Appointment Booking Agent stopped."


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  KEY CONCURRENCY MODEL
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Process 1: main process (Python asyncio event loop)
  â”œâ”€â”€ Task A: aiohttp server (avatar)     â† serves HTML, handles WebSockets
  â”œâ”€â”€ Task B: queue reader                â† reads avatar_queue, broadcasts
  â””â”€â”€ Task C: conversation_manager        â† mic â†’ STT â†’ LLM â†’ commands
              â””â”€â”€ run_in_executor          â† mic reads in thread pool
              â””â”€â”€ run_in_executor          â† avatar_queue.get in thread pool

  Process 2: speaker process (blocking, synchronous)
  â””â”€â”€ Polls mp_commands_queue
  â””â”€â”€ Calls CartesiaTTS.stream() (blocking WebSocket)
  â””â”€â”€ Calls PyAudio stream.write() (blocking audio I/O)

  Why two processes instead of two async tasks?
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  PyAudio's stream.write() is a BLOCKING C call. It cannot be awaited.
  Putting it in the same event loop would freeze STT + avatar server.
  A thread would help but risks GIL contention with audio timing.
  A separate process guarantees zero interference.

  Why run_in_executor for mic?
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  sounddevice's stream.__next__() is a blocking generator.
  Without executor, it would block the event loop on every iteration,
  preventing aiohttp from accepting WebSocket connections or sending
  avatar events. The executor runs it in a thread pool, yielding
  control back to the event loop between each 10ms chunk.


================================================================================
  END OF FLOW DOCUMENT
================================================================================